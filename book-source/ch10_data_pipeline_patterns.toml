# Chapter 10: Data Pipeline Patterns
# Complete source for generating 10_data_pipeline_patterns.md and examples

[chapter]
number = 10
title = "Data Pipeline Patterns"
description = "Real-world transformation patterns, best practices, and production-ready data processing workflows"

[chapter.learning_objectives]
summary = """
You've mastered Computo's operators, learned Permuto's templating, and explored advanced transformation techniques. Now it's time to bring it all together. This final chapter focuses on **real-world data pipeline patterns** - the battle-tested approaches that power production systems.

We'll explore complete workflows, error handling strategies, performance patterns, and integration techniques that transform your knowledge into robust, maintainable data processing solutions.
"""

operators_introduced = []  # No new operators - this chapter focuses on patterns

[chapter.sections]

[chapter.sections.pipeline_architecture]
title = "Pipeline Architecture Patterns"
content = '''
Data pipelines are more than single transformations - they're workflows that move data through multiple stages, each serving a specific purpose. Understanding common architecture patterns helps you design robust, maintainable systems.

#### The Three-Stage Pattern

Most successful data pipelines follow a three-stage architecture:

1. **Extract & Validate** - Ingest data and ensure it meets basic requirements
2. **Transform & Enrich** - Apply business logic and enhance data
3. **Format & Deliver** - Shape final output for consumption

```json
// Stage 1: Validation Pipeline
["let",
  [["validated_data", ["if", 
    ["&&", 
      ["!=", ["get", ["$input"], "/user_id"], null],
      [">", ["count", ["get", ["$input"], "/events"]], 0]
    ],
    ["$input"],
    ["obj", ["error", "Invalid input: missing user_id or events"]]
  ]]],
  ["$", "/validated_data"]
]
```

This pattern separates concerns cleanly and makes each stage testable independently.

#### The Template-Driven Pattern

For output formatting, the template-driven pattern provides maximum flexibility:

```json
// Stage 2: Data Preparation
["let",
  [["clean_context", ["obj",
    ["user", ["get", ["$input"], "/user_data"]],
    ["summary", ["reduce", ["get", ["$input"], "/events"], 0, ["lambda", ["acc", "event"], ["+", ["$", "/acc"], 1]]]]
  ]]],
  // Stage 3: Template Application  
  ["permuto.apply", <template>, ["$", "/clean_context"]]
]
```

#### Error Recovery Patterns

Production pipelines need graceful error handling:

```json
["let",
  [["safe_result", ["if",
    ["try_operation", ["$input"]],
    ["successful_transform", ["$input"]],
    ["error_fallback", ["$input"]]
  ]]],
  ["$", "/safe_result"]
]
```
'''

[chapter.sections.validation_strategies]
title = "Validation and Error Handling Strategies"
content = '''
Robust data pipelines anticipate and handle errors gracefully. Rather than failing catastrophically, they provide meaningful feedback and fallback behaviors.

#### Input Validation Patterns

**Schema Validation:**
```json
["let",
  [["is_valid", ["&&",
    ["!=", ["get", ["$input"], "/required_field"], null],
    [">=", ["count", ["get", ["$input"], "/items"]], 1],
    ["==", ["type", ["get", ["$input"], "/amount"]], "number"]
  ]]],
  ["if", ["$", "/is_valid"],
    ["process_valid_input", ["$input"]],
    ["obj", ["error", "Validation failed"], ["input", ["$input"]]]
  ]
]
```

**Range Validation:**
```json
["let",
  [["value", ["get", ["$input"], "/score"]],
   ["in_range", ["&&", [">=", ["$", "/value"], 0], ["<=", ["$", "/value"], 100]]]],
  ["if", ["$", "/in_range"],
    ["$", "/value"],
    ["obj", ["error", "Score must be between 0 and 100"], ["received", ["$", "/value"]]]
  ]
]
```

#### Safe Data Access

Use the `get` operator with default values to prevent null reference errors:

```json
["obj",
  ["user_name", ["get", ["$input"], "/user/name", "Unknown User"]],
  ["preferences", ["get", ["$input"], "/user/settings", {}]]
]
```

#### Error Context Preservation

When errors occur, preserve context for debugging:

```json
["obj",
  ["success", false],
  ["error_message", "Transformation failed"],
  ["input_snapshot", ["$input"]],
  ["step", "data_enrichment"],
  ["timestamp", ["now"]]
]
```
'''

[chapter.sections.performance_patterns]
title = "Performance Optimization Patterns"
content = '''
As data volumes grow, transformation performance becomes critical. These patterns help you build efficient, scalable pipelines.

#### Minimize Deep Nesting

Instead of deeply nested operations:
```json
// Inefficient - deep nesting
["get", ["get", ["get", ["$input"], "/data"], "/users"], "/0"]
```

Use `let` to flatten and cache intermediate results:
```json
// Efficient - cached intermediate values
["let",
  [["data", ["get", ["$input"], "/data"]],
   ["users", ["get", ["$", "/data"], "/users"]],
   ["first_user", ["get", ["$", "/users"], "/0"]]],
  ["$", "/first_user"]
]
```

#### Early Filtering

Filter data as early as possible to reduce processing overhead:

```json
// Filter first, then transform
["map", 
  ["filter", ["get", ["$input"], "/records"], 
    ["lambda", ["record"], [">", ["get", ["$", "/record"], "/amount"], 1000]]
  ],
  ["lambda", ["record"], ["expensive_transformation", ["$", "/record"]]]
]
```

#### Conditional Processing

Use short-circuit evaluation to avoid unnecessary work:

```json
["if", 
  ["&&", 
    ["get", ["$input"], "/should_process"],
    [">", ["count", ["get", ["$input"], "/items"]], 0]
  ],
  ["expensive_processing", ["$input"]],
  ["simple_passthrough", ["$input"]]
]
```

#### Batch-Friendly Patterns

Design transformations that work efficiently on large datasets:

```json
// Process entire arrays efficiently
["map", ["get", ["$input"], "/user_events"],
  ["lambda", ["event"],
    ["obj",
      ["user_id", ["get", ["$", "/event"], "/user"]],
      ["type", ["get", ["$", "/event"], "/action"]],
      ["value", ["get", ["$", "/event"], "/data/amount", 0]]
    ]
  ]
]
```
'''

[chapter.sections.testing_strategies]
title = "Testing and Validation Strategies"
content = '''
Reliable data pipelines require comprehensive testing. Here are patterns for validating transformation logic at multiple levels.

#### Unit Testing Individual Transformations

Test small, focused transformations with known inputs and expected outputs:

```json
// Test: User name formatting
// Input: {"first": "John", "last": "Doe"}
// Expected: "John Doe"
["str_concat", 
  ["get", ["$input"], "/first"], 
  " ", 
  ["get", ["$input"], "/last"]
]
```

#### Integration Testing Pipelines

Test complete workflows end-to-end:

```json
// Test: Complete user enrichment pipeline
// Input: Raw user data
// Expected: Formatted user profile with calculated fields
["let",
  [["validated", ["validate_user", ["$input"]]],
   ["enriched", ["enrich_user_data", ["$", "/validated"]]],
   ["formatted", ["format_user_profile", ["$", "/enriched"]]]],
  ["$", "/formatted"]
]
```

#### Property-Based Testing

Test transformation properties that should always hold:

```json
// Property: Output count should equal input count for mappings
["let",
  [["input_count", ["count", ["get", ["$input"], "/items"]]],
   ["output", ["map", ["get", ["$input"], "/items"], ["lambda", ["x"], ["transform", ["$", "/x"]]]]],
   ["output_count", ["count", ["$", "/output"]]]],
  ["==", ["$", "/input_count"], ["$", "/output_count"]]
]
```

#### Error Case Testing

Verify graceful handling of edge cases:

```json
// Test: Empty input handling
// Input: {"items": []}
// Expected: {"result": [], "count": 0}
["obj",
  ["result", ["get", ["$input"], "/items", []]],
  ["count", ["count", ["get", ["$input"], "/items", []]]]
]
```

#### Regression Testing

Maintain test suites that catch regressions:

```json
// Regression test: Ensure currency formatting doesn't break
// Input: {"amount_cents": 12345}
// Expected: "USD $123.45"
["str_concat", 
  "USD $", 
  ["/", ["get", ["$input"], "/amount_cents"], 100]
]
```
'''

[chapter.sections.integration_patterns]
title = "Integration and Deployment Patterns"
content = '''
Production systems require reliable integration patterns. These approaches help you embed transformations into larger applications and services.

#### API Gateway Pattern

Use transformations to standardize API responses:

```json
// Transform internal API format to public API format
["let",
  [["internal_data", ["$input"]],
   ["public_format", ["obj",
     ["id", ["get", ["$", "/internal_data"], "/uuid"]],
     ["name", ["get", ["$", "/internal_data"], "/display_name"]],
     ["status", ["if", ["get", ["$", "/internal_data"], "/is_active"], "active", "inactive"]]
   ]]],
  ["permuto.apply",
    {
      "data": "${/public_format}",
      "meta": {
        "version": "v1",
        "transformed_at": "${/timestamp}"
      }
    },
    ["obj", ["public_format", ["$", "/public_format"]], ["timestamp", ["now"]]]
  ]
]
```

#### Event Stream Processing

Transform events as they flow through your system:

```json
// Enrich events with contextual data
["let",
  [["event", ["$input"]],
   ["user_context", ["lookup_user", ["get", ["$", "/event"], "/user_id"]]],
   ["enriched_event", ["obj",
     ["original", ["$", "/event"]],
     ["user_name", ["get", ["$", "/user_context"], "/name"]],
     ["user_segment", ["get", ["$", "/user_context"], "/segment"]],
     ["processed_at", ["now"]]
   ]]],
  ["$", "/enriched_event"]
]
```

#### Batch Processing Pattern

Handle large datasets efficiently:

```json
// Process records in batches with progress tracking
["let",
  [["records", ["get", ["$input"], "/batch"]],
   ["processed", ["map", ["$", "/records"],
     ["lambda", ["record"],
       ["obj",
         ["id", ["get", ["$", "/record"], "/id"]],
         ["result", ["process_record", ["$", "/record"]]],
         ["status", "completed"]
       ]
     ]
   ]]],
  ["obj",
    ["batch_id", ["get", ["$input"], "/batch_id"]],
    ["processed_count", ["count", ["$", "/processed"]]],
    ["results", ["$", "/processed"]]
  ]
]
```

#### Configuration Management

Use transformations to process configuration files:

```json
// Transform environment-specific config
["let",
  [["base_config", ["get", ["$input"], "/base"]],
   ["env_overrides", ["get", ["$input"], "/environments/production"]],
   ["merged_config", ["merge", ["$", "/base_config"], ["$", "/env_overrides"]]]],
  ["permuto.apply",
    {
      "database": {
        "host": "${/database/host}",
        "port": "${/database/port}",
        "ssl": true
      },
      "api": {
        "base_url": "${/api/base_url}",
        "timeout": "${/api/timeout}"
      }
    },
    ["$", "/merged_config"]
  ]
]
```
'''

# =============================================================================
# EXAMPLES
# =============================================================================

[[chapter.examples]]
name = "user_data_pipeline"
section = "pipeline_architecture"
description = "Complete user data processing pipeline with validation, enrichment, and formatting"
script = '''
["let",
  [
    ["validation_result", ["if",
      ["&&",
        ["!=", ["get", ["$input"], "/user_id"], null],
        ["!=", ["get", ["$input"], "/email"], null],
        [">", ["count", ["get", ["$input"], "/events"]], 0]
      ],
      ["obj", ["valid", true], ["data", ["$input"]]],
      ["obj", ["valid", false], ["error", "Missing required fields"]]
    ]],
    ["processed", ["if", ["get", ["$", "/validation_result"], "/valid"],
      ["let",
        [
          ["user_data", ["get", ["$", "/validation_result"], "/data"]],
          ["event_count", ["count", ["get", ["$", "/user_data"], "/events"]]],
          ["clean_context", ["obj",
            ["user_id", ["get", ["$", "/user_data"], "/user_id"]],
            ["email", ["get", ["$", "/user_data"], "/email"]],
            ["activity_level", ["if", [">", ["$", "/event_count"], 10], "high", "normal"]],
            ["event_count", ["$", "/event_count"]]
          ]]
        ],
        ["permuto.apply",
          {
            "profile": {
              "id": "${/user_id}",
              "contact": "${/email}",
              "engagement": "${/activity_level}",
              "stats": {
                "total_events": "${/event_count}"
              }
            }
          },
          ["$", "/clean_context"]
        ]
      ],
      ["$", "/validation_result"]
    ]]
  ],
  ["$", "/processed"]
]
'''
input = {user_id = "u-123", email = "alice@example.com", events = [{type = "login"}, {type = "view"}, {type = "purchase"}]}
expected = {profile = {id = "u-123", contact = "alice@example.com", engagement = "normal", stats = {total_events = 3}}}
cli_flags = ["--interpolation"]

[[chapter.examples]]
name = "safe_data_access"
section = "validation_strategies"
description = "Defensive data access with fallbacks and error handling"
script = '''
["obj",
  ["user_name", ["get", ["$input"], "/user/profile/name", "Anonymous"]],
  ["user_email", ["get", ["$input"], "/user/contact/email", "no-email@example.com"]],
  ["preferences", ["get", ["$input"], "/user/settings/preferences", {}]],
  ["score", ["let",
    [["raw_score", ["get", ["$input"], "/user/metrics/score"]]],
    ["if", ["&&", ["!=", ["$", "/raw_score"], null], [">=", ["$", "/raw_score"], 0]],
      ["$", "/raw_score"],
      0
    ]
  ]],
  ["status", ["if", ["get", ["$input"], "/user/is_active", false], "active", "inactive"]]
]
'''
input = {user = {profile = {name = "Bob"}, is_active = true}}
expected = {user_name = "Bob", user_email = "no-email@example.com", preferences = {}, score = 0, status = "active"}

[[chapter.examples]]
name = "input_validation"
section = "validation_strategies"
description = "Comprehensive input validation with detailed error reporting"
script = '''
["let",
  [
    ["required_fields_check", ["&&",
      ["!=", ["get", ["$input"], "/user_id"], null],
      ["!=", ["get", ["$input"], "/amount"], null],
      ["!=", ["get", ["$input"], "/transaction_type"], null]
    ]],
    ["amount_validation", ["let",
      [["amount", ["get", ["$input"], "/amount"]]],
      ["&&", ["!=", ["$", "/amount"], null], [">", ["$", "/amount"], 0]]
    ]],
    ["type_validation", ["let",
      [["type", ["get", ["$input"], "/transaction_type"]]],
      ["||", ["==", ["$", "/type"], "deposit"], ["==", ["$", "/type"], "withdrawal"]]
    ]],
    ["all_valid", ["&&", ["$", "/required_fields_check"], ["$", "/amount_validation"], ["$", "/type_validation"]]]
  ],
  ["if", ["$", "/all_valid"],
    ["obj",
      ["status", "valid"],
      ["data", ["obj",
        ["user_id", ["get", ["$input"], "/user_id"]],
        ["amount", ["get", ["$input"], "/amount"]],
        ["type", ["get", ["$input"], "/transaction_type"]],
        ["validated_at", "2024-01-15T10:30:00Z"]
      ]]
    ],
    ["obj",
      ["status", "invalid"],
      ["errors", ["obj",
        ["missing_required", ["not", ["$", "/required_fields_check"]]],
        ["invalid_amount", ["not", ["$", "/amount_validation"]]],
        ["invalid_type", ["not", ["$", "/type_validation"]]]
      ]],
      ["input", ["$input"]]
    ]
  ]
]
'''
input = {user_id = "u-456", amount = 100, transaction_type = "deposit"}
expected = {status = "valid", data = {user_id = "u-456", amount = 100, type = "deposit", validated_at = "2024-01-15T10:30:00Z"}}

[[chapter.examples]]
name = "performance_optimization"
section = "performance_patterns"
description = "Optimized data processing with early filtering and caching"
script = '''
["let",
  [
    ["raw_transactions", ["get", ["$input"], "/transactions"]],
    ["high_value_transactions", ["filter", ["$", "/raw_transactions"],
      ["lambda", ["tx"], [">", ["get", ["$", "/tx"], "/amount"], 1000]]
    ]],
    ["processed_transactions", ["map", ["$", "/high_value_transactions"],
      ["lambda", ["tx"],
        ["let",
          [
            ["amount", ["get", ["$", "/tx"], "/amount"]],
            ["fee", ["*", ["$", "/amount"], 0.025]]
          ],
          ["obj",
            ["id", ["get", ["$", "/tx"], "/id"]],
            ["amount", ["$", "/amount"]],
            ["fee", ["$", "/fee"]],
            ["net_amount", ["-", ["$", "/amount"], ["$", "/fee"]]],
            ["category", "high_value"]
          ]
        ]
      ]
    ]],
    ["summary", ["reduce", ["$", "/processed_transactions"], 
      ["obj", ["count", 0], ["total_amount", 0], ["total_fees", 0]],
      ["lambda", ["acc", "tx"],
        ["obj",
          ["count", ["+", ["get", ["$", "/acc"], "/count"], 1]],
          ["total_amount", ["+", ["get", ["$", "/acc"], "/total_amount"], ["get", ["$", "/tx"], "/amount"]]],
          ["total_fees", ["+", ["get", ["$", "/acc"], "/total_fees"], ["get", ["$", "/tx"], "/fee"]]]
        ]
      ]
    ]]
  ],
  ["obj",
    ["high_value_transactions", ["$", "/processed_transactions"]],
    ["summary", ["$", "/summary"]]
  ]
]
'''
input = {transactions = [{id = "tx-1", amount = 1500}, {id = "tx-2", amount = 500}, {id = "tx-3", amount = 2000}]}
expected = {high_value_transactions = [{id = "tx-1", amount = 1500, fee = 37.5, net_amount = 1462.5, category = "high_value"}, {id = "tx-3", amount = 2000, fee = 50, net_amount = 1950, category = "high_value"}], summary = {count = 2, total_amount = 3500, total_fees = 87.5}}

[[chapter.examples]]
name = "api_transformation"
section = "integration_patterns"
description = "Transform internal API data to standardized external format"
script = '''
["let",
  [
    ["internal_user", ["get", ["$input"], "/user_record"]],
    ["permissions", ["get", ["$input"], "/user_permissions"]],
    ["activity", ["get", ["$input"], "/recent_activity"]],
    ["clean_context", ["obj",
      ["user_id", ["get", ["$", "/internal_user"], "/uuid"]],
      ["display_name", ["str_concat", 
        ["get", ["$", "/internal_user"], "/first_name"], 
        " ", 
        ["get", ["$", "/internal_user"], "/last_name"]
      ]],
      ["email", ["get", ["$", "/internal_user"], "/email_address"]],
      ["role", ["get", ["$", "/permissions"], "/primary_role"]],
      ["is_active", ["get", ["$", "/internal_user"], "/status_active"]],
      ["last_login", ["get", ["$", "/activity"], "/last_login_timestamp"]],
      ["api_version", "v2"]
    ]]
  ],
  ["permuto.apply",
    {
      "user": {
        "id": "${/user_id}",
        "name": "${/display_name}",
        "email": "${/email}",
        "role": "${/role}",
        "status": "${/is_active}",
        "last_seen": "${/last_login}"
      },
      "meta": {
        "api_version": "${/api_version}",
        "generated_at": "2024-01-15T10:30:00Z"
      }
    },
    ["$", "/clean_context"]
  ]
]
'''
input = {user_record = {uuid = "u-789", first_name = "Carol", last_name = "Williams", email_address = "carol@corp.com", status_active = true}, user_permissions = {primary_role = "admin"}, recent_activity = {last_login_timestamp = "2024-01-14T09:15:00Z"}}
expected = {user = {id = "u-789", name = "Carol Williams", email = "carol@corp.com", role = "admin", status = true, last_seen = "2024-01-14T09:15:00Z"}, meta = {api_version = "v2", generated_at = "2024-01-15T10:30:00Z"}}
cli_flags = ["--interpolation"]

[[chapter.examples]]
name = "batch_processing"
section = "integration_patterns"
description = "Process batch of records with error handling and progress tracking"
script = '''
["let",
  [
    ["batch_data", ["get", ["$input"], "/records"]],
    ["batch_id", ["get", ["$input"], "/batch_id"]],
    ["processed_records", ["map", ["$", "/batch_data"],
      ["lambda", ["record"],
        ["let",
          [
            ["record_id", ["get", ["$", "/record"], "/id"]],
            ["is_valid", ["&&",
              ["!=", ["get", ["$", "/record"], "/name"], null],
              [">", ["get", ["$", "/record"], "/amount", 0], 0]
            ]]
          ],
          ["if", ["$", "/is_valid"],
            ["obj",
              ["id", ["$", "/record_id"]],
              ["status", "success"],
              ["result", ["obj",
                ["name", ["get", ["$", "/record"], "/name"]],
                ["amount", ["get", ["$", "/record"], "/amount"]],
                ["processed_amount", ["*", ["get", ["$", "/record"], "/amount"], 1.1]]
              ]]
            ],
            ["obj",
              ["id", ["$", "/record_id"]],
              ["status", "error"],
              ["error", "Invalid record: missing name or invalid amount"]
            ]
          ]
        ]
      ]
    ]],
    ["success_count", ["count", ["filter", ["$", "/processed_records"],
      ["lambda", ["result"], ["==", ["get", ["$", "/result"], "/status"], "success"]]
    ]]],
    ["error_count", ["count", ["filter", ["$", "/processed_records"],
      ["lambda", ["result"], ["==", ["get", ["$", "/result"], "/status"], "error"]]
    ]]]
  ],
  ["obj",
    ["batch_id", ["$", "/batch_id"]],
    ["total_records", ["count", ["$", "/batch_data"]]],
    ["successful", ["$", "/success_count"]],
    ["failed", ["$", "/error_count"]],
    ["results", ["$", "/processed_records"]]
  ]
]
'''
input = {batch_id = "batch-001", records = [{id = "r1", name = "Item A", amount = 100}, {id = "r2", name = "Item B"}, {id = "r3", name = "Item C", amount = 250}]}
expected = {batch_id = "batch-001", total_records = 3, successful = 2, failed = 1, results = [{id = "r1", status = "success", result = {name = "Item A", amount = 100, processed_amount = 110}}, {id = "r2", status = "error", error = "Invalid record: missing name or invalid amount"}, {id = "r3", status = "success", result = {name = "Item C", amount = 250, processed_amount = 275}}]}

[chapter.summary]
content = '''
### In This Chapter

You've learned the essential patterns for building production-ready data pipelines:

- **Pipeline Architecture Patterns** - Three-stage workflows, template-driven design, and error recovery
- **Validation and Error Handling** - Input validation, safe data access, and meaningful error reporting  
- **Performance Optimization** - Early filtering, caching strategies, and batch-friendly patterns
- **Testing Strategies** - Unit testing, integration testing, and regression prevention
- **Integration Patterns** - API gateways, event processing, and configuration management

**Key Principles for Production Systems:**

1. **Validate Early** - Catch errors at input boundaries
2. **Fail Gracefully** - Provide meaningful error messages and fallback behaviors
3. **Optimize for Scale** - Design patterns that work efficiently with large datasets
4. **Test Comprehensively** - Cover normal cases, edge cases, and error scenarios
5. **Integrate Thoughtfully** - Design for maintainable, monitorable production deployment

**The Complete Toolkit:**

You now have the complete Computo and Permuto toolkit - **35 operators** and battle-tested patterns for:
- Data validation and cleaning
- Complex business logic implementation  
- Template-driven output formatting
- Error handling and recovery
- Performance optimization
- Production integration

Whether you're building ETL pipelines, API transformations, configuration processors, or real-time data services, these patterns provide the foundation for robust, maintainable data processing systems.

**Computo prepares the data, Permuto presents the data, and these patterns make it production-ready.**
''' 